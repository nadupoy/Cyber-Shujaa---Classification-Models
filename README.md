# ğŸ•¸ï¸ Cyber Shujaa - Classification Models ğŸš€

This is my solution to the week 8 assignment in the Cyber Shujaa program 
for the **Data and AI Specialist** track.

## ğŸ§­ Table of contents

- [ğŸŒŸ Overview](#ğŸŒŸ-overview)
  - [The assignment ğŸ¯](#the-assignment-ğŸ¯)
  - [Links ğŸ”—](#links-ğŸ”—)
- [ğŸ› ï¸ My process](#ğŸ› ï¸-my-process)
  - [Built with ğŸ§±](#built-with-ğŸ§±)
  - [What I learned ğŸ§ ](#what-i-learned-ğŸ§ )
  - [Continued development ğŸŒ±](#continued-development-ğŸŒ±)
  - [Useful resources ğŸ“š](#useful-resources-ğŸ“š)
- [ğŸ‘©â€ğŸ’» Author](#ğŸ‘©â€ğŸ’»-author)

## ğŸŒŸ Overview

### The assignment ğŸ¯

In this assignment, we applied our understanding of **supervised machine learning 
classification models** by building and evaluating various models. Using the Wine 
dataset from `scikit-learn`, we explored and visualized the data, and trained six 
different models:

- Logistic Regression
- Decision Tree
- Random Forest
- K-Nearest Neighbours (KNN)
- Naive Bayes
- Support Vector Machine (SVM)

Our goal was to compare their performance using standard evaluation metrics and 
confusion matrices, and to interpret which model works best and why.

This assignment would help us understand not just how to train models, but how to 
assess and compare their performance on the same dataset under similar conditions.

We were required to complete the following tasks:
1. **Load the dataset** 
2. **Explore the Dataset:** Perform exploratory data analysis (EDA) to understand 
feature relationships and class distributions.
3. **Prepare the Data:** Handle missing values (if any) and split the dataset into 
training and test sets.
4. **Build the Models:** Implement the following classification models: 
	- Logistic Regression
	- Decision Tree
	- Random Forest
	- K-Nearest Neighbours (KNN)
	- Naive Bayes
	- Support Vector Machine (SVM)
5.	**Evaluate the Models:** Use evaluation parameters: 
	- Accuracy score
	- Classification report (precision, recall, F1-score)
	- Confusion matrix (with visual plots)
6.	**Compare the models:** Analyse the results and explain which performs better


### Links ğŸ”—

- [Google Colab]() assignment submission

## ğŸ› ï¸ My process

### Built with ğŸ§±

- **[Python](https://www.python.org)** ğŸ
- **[Pandas](https://pandas.pydata.org/docs/index.html)** Python library used for 
working with data sets with functions for cleaning, exploring and manipulating data. ğŸ¼
- **[Matplotlib](https://matplotlib.org/stable/)**, a comprehensive Python library for creating static, animated and interactive visualizations.
- **[`scikit-learn`](https://scikit-learn.org/stable/index.html)**, for machine learning and predictive data analysis in Python.

### What I learned ğŸ§ 

**1. Loading a toy dataset in `scikit-learn` as a Pandas `DataFrame`**

The [wine dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) was used for this assignment:

```python
	wine_dataset = load_wine(return_X_y=True, as_frame=True)
```

### Continued development ğŸŒ±

### Useful resources ğŸ“š

## ğŸ‘©â€ğŸ’» Author

- LinkedIn - [Grace Sampao](https://www.linkedin.com/in/grace-sampao)
- GitHub - [@nadupoy](https://github.com/nadupoy)
- X (formerly Twitter) - [@grace_sampao](https://x.com/grace_sampao)
- [Blog](https://nadupoy.github.io/)
